{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_pipeline import transformation_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('content/preprocessed_train.csv')\n",
    "\n",
    "# let's pick the data wiht primary_use==0\n",
    "data = data.query('primary_use==0 & meter==0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "b_id = [118, 646, 125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_output(actual, predicted, title, building_idx, avg_loss, avg_rmse):\n",
    "    fig, (ax1, ax2, ax) = plt.subplots(3, 1,  figsize=(30, 15), sharex=True)\n",
    "\n",
    "    fig.suptitle(\n",
    "        f'{title} model for building {building_idx}\\nmse={avg_loss:.5f}\\nrmse={avg_rmse:.5f}', fontsize=24)\n",
    "\n",
    "    ax1.plot(range(len(actual)),\n",
    "             predicted,\n",
    "             color='green', linestyle='dashed')\n",
    "    ax1.set_title('Predicted')\n",
    "    ax1.set_ylim(0, 1)\n",
    "\n",
    "    ax2.plot(range(len(actual)),\n",
    "             actual,\n",
    "             color='red', label='Actual')\n",
    "    ax2.set_title('Actual')\n",
    "    ax2.set_ylim(0, 1)\n",
    "\n",
    "    ax.plot(range(len(actual)),\n",
    "            predicted,\n",
    "            color='green', linestyle='dashed',\n",
    "            label='Predicted')\n",
    "\n",
    "    ax.plot(range(len(actual)),\n",
    "            actual,\n",
    "            color='red',\n",
    "            label='actual')\n",
    "    ax.set_ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    fig.savefig(\n",
    "        f'Final Plots for the research/train on 70 until best/{title} model -- building {building_idx} -- mse {avg_loss:.5f} -- rmse {avg_rmse:.5f}.png')\n",
    "\n",
    "# %%\n",
    "\n",
    "# function to laod certain building id\n",
    "\n",
    "\n",
    "def loading_data(idx, train_size):\n",
    "    pipeline, data_cleaned = transformation_pipeline(\n",
    "        data, building_id=idx, meter=0, primary_use=0)\n",
    "\n",
    "    train, test = train_test_split(data_cleaned,\n",
    "                                   # [:, 1:],\n",
    "                                   #transformed_data[:, 0],\n",
    "                                   train_size=train_size,\n",
    "                                   shuffle=False,\n",
    "                                   random_state=2021)\n",
    "\n",
    "    train_data = pipeline.fit_transform(train)\n",
    "    test_data = pipeline.transform(test)\n",
    "\n",
    "    x_train, y_train = train_data[:, 1:], train_data[:, 0]\n",
    "\n",
    "    x_val, y_val = test_data[:, 1:], test_data[:, 0]\n",
    "\n",
    "    train_gen = tf.keras.preprocessing.sequence.TimeseriesGenerator(x_train,\n",
    "                                                                    y_train,\n",
    "                                                            length=6, sampling_rate=1,\n",
    "                                                             stride=1,\n",
    "                                                             batch_size=32,\n",
    "                                                                shuffle=False)\n",
    "\n",
    "    val_gen = tf.keras.preprocessing.sequence.TimeseriesGenerator(x_val,\n",
    "                                                                  y_val,\n",
    "                                                      length=6, sampling_rate=1,\n",
    "                                                      stride=1, batch_size=350,\n",
    "                                                      shuffle=False\n",
    "                                                      )\n",
    "    return train_gen, val_gen[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "\n",
    "def build_model(\n",
    "        input_shape,\n",
    "        head_size,\n",
    "        num_heads,\n",
    "        ff_dim,\n",
    "        num_transformer_blocks,\n",
    "        mlp_units,\n",
    "        dropout=0,\n",
    "        mlp_dropout=0,\n",
    "):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# %% function to return models\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "def create_model(model_name):\n",
    "    if model_name == 'gru':\n",
    "        model = tf.keras.Sequential([tf.keras.layers.GRU(128, activation='relu',\n",
    "                                                         return_sequences=False),\n",
    "                                     tf.keras.layers.Dense(1)])\n",
    "    elif model_name == 'lstm':\n",
    "\n",
    "        model = tf.keras.Sequential([tf.keras.layers.LSTM(128, activation='relu',\n",
    "                                                          return_sequences=False),\n",
    "                                     tf.keras.layers.Dense(1)])\n",
    "    elif model_name == 'rnn':\n",
    "\n",
    "        model = tf.keras.Sequential([tf.keras.layers.SimpleRNN(128, activation='relu',\n",
    "                                                      return_sequences=False),\n",
    "                                 tf.keras.layers.Dense(1)])\n",
    "    elif model_name == 'transformer':\n",
    "        model = build_model(\n",
    "            (6, 14),  # 6 is for the window on our data 6 hours, and 11 for the features\n",
    "            head_size=256,  # play with this\n",
    "            num_heads=8,  # and this\n",
    "            ff_dim=128,  # and this\n",
    "            num_transformer_blocks=1,  # and this\n",
    "            mlp_units=[256],\n",
    "            mlp_dropout=0.0,\n",
    "            dropout=0.0,\n",
    "        )\n",
    "\n",
    "    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(0.0001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shomer\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\shomer\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "d:\\projects\\Research-Buildings-Energy-forecasting-using-Deep-Learning\\data_fetcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['season'] = df.month.apply(self.season_finder)\n",
      "d:\\projects\\Research-Buildings-Energy-forecasting-using-Deep-Learning\\data_fetcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['weekend'] = df.timestamp.dt.dayofweek > 4\n",
      "d:\\projects\\Research-Buildings-Energy-forecasting-using-Deep-Learning\\data_fetcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['day_of_the_week'] = df.timestamp.dt.dayofweek\n",
      "C:\\Users\\shomer\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\shomer\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "d:\\projects\\Research-Buildings-Energy-forecasting-using-Deep-Learning\\data_fetcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['season'] = df.month.apply(self.season_finder)\n",
      "d:\\projects\\Research-Buildings-Energy-forecasting-using-Deep-Learning\\data_fetcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['weekend'] = df.timestamp.dt.dayofweek > 4\n",
      "d:\\projects\\Research-Buildings-Energy-forecasting-using-Deep-Learning\\data_fetcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['day_of_the_week'] = df.timestamp.dt.dayofweek\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "350\n",
      "350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shomer\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "C:\\Users\\shomer\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "d:\\projects\\Research-Buildings-Energy-forecasting-using-Deep-Learning\\data_fetcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['season'] = df.month.apply(self.season_finder)\n",
      "d:\\projects\\Research-Buildings-Energy-forecasting-using-Deep-Learning\\data_fetcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['weekend'] = df.timestamp.dt.dayofweek > 4\n",
      "d:\\projects\\Research-Buildings-Energy-forecasting-using-Deep-Learning\\data_fetcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['day_of_the_week'] = df.timestamp.dt.dayofweek\n"
     ]
    }
   ],
   "source": [
    "for building_idx in b_id:\n",
    "    train_gen, test_gen = loading_data(building_idx, 0.2)\n",
    "    print( len( test_gen[0] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer Model \n",
      "building: 118 \n",
      "mse= 0.021322924598430104 \n",
      "rmse] 0.14602371245256746 \n",
      "mape= 0.3119527011828904\n",
      "----------\n",
      "GRU Model \n",
      "building: 118 \n",
      "mse= 0.010377105764972546 \n",
      "rmse] 0.1018680802065718 \n",
      "mape= 0.2089818205261151\n",
      "----------\n",
      "LSTM Model \n",
      "building: 118 \n",
      "mse= 0.011533676898691371 \n",
      "rmse] 0.10739495751054316 \n",
      "mape= 0.22505276202970678\n",
      "----------\n",
      "RNN Model \n",
      "building: 118 \n",
      "mse= 0.01930145430051928 \n",
      "rmse] 0.138929673938001 \n",
      "mape= 0.2923522444843031\n",
      "----------\n",
      "Transformer Model \n",
      "building: 646 \n",
      "mse= 0.00803858655581144 \n",
      "rmse] 0.08965816502589957 \n",
      "mape= 0.674794332403073\n",
      "----------\n",
      "GRU Model \n",
      "building: 646 \n",
      "mse= 0.017482953856383848 \n",
      "rmse] 0.13222312148933654 \n",
      "mape= 1.5579199831200032\n",
      "----------\n",
      "LSTM Model \n",
      "building: 646 \n",
      "mse= 0.04527680066299689 \n",
      "rmse] 0.2127834595615855 \n",
      "mape= 1.0689734226916403\n",
      "----------\n",
      "RNN Model \n",
      "building: 646 \n",
      "mse= 0.09467397060783775 \n",
      "rmse] 0.30769135608241865 \n",
      "mape= 1.988073365079332\n",
      "----------\n",
      "Transformer Model \n",
      "building: 125 \n",
      "mse= 0.008320998861512508 \n",
      "rmse] 0.09121950921547708 \n",
      "mape= 0.12950459726313487\n",
      "----------\n",
      "GRU Model \n",
      "building: 125 \n",
      "mse= 0.009558499591918752 \n",
      "rmse] 0.09776757945207988 \n",
      "mape= 0.13909272276017584\n",
      "----------\n",
      "LSTM Model \n",
      "building: 125 \n",
      "mse= 0.008424561021589554 \n",
      "rmse] 0.09178540745450528 \n",
      "mape= 0.14900319785234067\n",
      "----------\n",
      "RNN Model \n",
      "building: 125 \n",
      "mse= 0.04878734500883398 \n",
      "rmse] 0.2208785752598789 \n",
      "mape= 0.3282833472552916\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "# %% loading models to evaluate them on new data\n",
    "import time\n",
    "models = ['models/Transformer_adam',\n",
    "          'models/GRU_ADAM',\n",
    "          'models/LSTM_ADAM',\n",
    "          'models/RNN_ADAM']\n",
    "finetuning_data = {}\n",
    "for building_idx in b_id:\n",
    "    train_gen, test_gen = loading_data(building_idx, 0.2)\n",
    "    finetuning_data[building_idx] = {}\n",
    "    for model_address in models:\n",
    "        predicted = np.array([])\n",
    "        actual = np.array([])\n",
    "        cb = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                              patience=15,\n",
    "                                              restore_best_weights=True)\n",
    "        txt = model_address.split('/')[1].split('_')[0]\n",
    "\n",
    "        finetuning_data[building_idx][txt] = []\n",
    "\n",
    "        model = create_model(txt.lower())\n",
    "\n",
    "        #start_time = time.time()\n",
    "\n",
    "        model.fit(train_gen,validation_data=test_gen, epochs=150,\n",
    "                  verbose=False,\n",
    "                    callbacks=[cb], )\n",
    "        #time_taken = time.time() - start_time\n",
    "        #print(f\"model {txt} took {time.time() - start_time} seconds\")\n",
    "\n",
    "        predicted = np.append(predicted, model.predict(test_gen[0]))\n",
    "        actual = np.append(actual, test_gen[1])\n",
    "\n",
    "        avg_mse = np.mean((actual - predicted)**2)\n",
    "        avg_rmse = np.sqrt(np.mean((actual - predicted)**2))\n",
    "        mape= np.mean(np.abs(np.divide((predicted - actual),(actual + 1e-15))))\n",
    "\n",
    "        #finetuning_data[building_idx][txt].append(\n",
    "        #    (avg_mse, avg_rmse, mape))\n",
    "        print(f'{txt} Model \\nbuilding: {building_idx} \\nmse= {avg_mse} \\nrmse] {avg_rmse} \\nmape= {mape}\\n----------')\n",
    "\n",
    "        #plot_output(actual, predicted, txt, building_idx, avg_mse, avg_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# transformer, gru, lstm,rnn = [], [], [],[]\n",
    "# for building_idx in b_id:\n",
    "\n",
    "#     x, y, z,r = finetuning_data[building_idx].values()\n",
    "#     transformer.append(x)\n",
    "#     gru.append(y)\n",
    "#     lstm.append(z)\n",
    "#     rnn.append(r)\n",
    "# # %%\n",
    "# mse, rmse, t = [], [], []\n",
    "# for d in [transformer, gru, lstm,rnn]:\n",
    "#     for i in range(3):\n",
    "\n",
    "#         mse.append(d[i][0][0])\n",
    "#         rmse.append(d[i][0][1])\n",
    "#         t.append(d[i][0][2])\n",
    "\n",
    "#     d.append([np.mean(mse), np.mean(rmse), np.mean(t)])\n",
    "\n",
    "# # %%\n",
    "# for d, n in zip([transformer, gru, lstm,rnn], ['transformer', 'gru',\n",
    "#                                                'lstm','rnn']):\n",
    "#     print(f'--- {n} ---')\n",
    "#     print(' mse \\t rmse \\t mape')\n",
    "#     print(f'{d[3][0]:0.4f}\\t{d[3][1]:0.4f}\\t{d[3][2]:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
